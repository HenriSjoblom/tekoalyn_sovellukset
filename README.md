#Tekoälyn sovellukset

Projekti mahdollistaa kielimallien ajamisen paikallisesti [langchain](https://python.langchain.com/) ja [llama.cpp](https://github.com/ggerganov/llama.cpp) -framworkkien avulla. Suorittamalla Jupyter notebook tiedoston llama solut, on mahdollista ajaa LLaMA 2 kielimallia tai muita llama.ccp framworkin tukemia kielimalleja, jotka ovat GGUF formaatissa.
Kielimallin täytyy löytyä määritellystä polusta. Mallikoodissa käytetty kielimalli on ladattu [Hugging Face](https://huggingface.co/) -sivustolta. Käytetty kielimalli on [LLaMa2-7b-chat](https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF).
